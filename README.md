# ğŸ¢ Enterprise Data Integration Platform

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-12+-316192.svg)](https://www.postgresql.org/)
[![Data Quality](https://img.shields.io/badge/Data%20Quality-95.6%25-brightgreen.svg)](reports/)

> A production-ready enterprise data warehouse showcasing end-to-end ETL pipeline development, dimensional modeling (Kimball), and comprehensive data quality management.

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Technology Stack](#-technology-stack)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Database Schema](#-database-schema)
- [Data Quality](#-data-quality)
- [Documentation](#-documentation)

---

## ğŸ¯ Overview

This project demonstrates **professional data engineering practices** through a complete data warehouse implementation. Built with PostgreSQL and Python, it processes data from multiple source systems into a star schema optimized for business intelligence and analytics.

### Business Context

The platform integrates data from three operational systems:

| Source System | Data Type | Volume |
|--------------|-----------|--------|
| ğŸª **CRM System** | Customer master data | 50,000 customers |
| ğŸ›’ **E-commerce Platform** | Transaction & product data | 200,000+ transactions |
| ğŸ“§ **Marketing System** | Campaign performance | 25 campaigns, 14,000+ responses |

### What Makes This Project Stand Out

- âœ… **Production-Grade Code**: Error handling, logging (loguru), configuration management
- âœ… **Advanced SCD Implementation**: Type 1 (products) and Type 2 (customers with full history)
- âœ… **Data Quality Engine**: 15 validation rules across 7 quality dimensions (95.6% score)
- âœ… **Interactive Dashboards**: HTML reports with embedded charts using matplotlib
- âœ… **Scalable Design**: Modular architecture with staging â†’ transformation â†’ warehouse layers

**Project Status:** âœ… Production-Ready | ğŸ“Š 95.6% Quality Score | ğŸ“ 685K+ Records Processed

---

## âœ¨ Key Features

### ğŸ”„ ETL Pipeline
- **Multi-stage architecture**: Staging â†’ Transformation â†’ Warehouse layers
- **Batch processing**: Handles 200K+ transactions efficiently
- **Change detection**: MD5 row hashing for data integrity
- **Audit trails**: Complete lineage tracking in `stg_audit_log`

### ğŸ“Š Dimensional Model
- **Star schema**: 4 dimensions + 2 facts + 1 aggregate
- **SCD Type 1**: Products/campaigns (overwrite changes)
- **SCD Type 2**: Customers with `valid_from/valid_to` for historical accuracy
- **Date dimension**: Pre-populated 2020-2030 with calendar attributes

### ğŸ¯ Data Quality
- **7 Quality Dimensions**: Completeness, Accuracy, Consistency, Validity, Uniqueness, Timeliness, Integrity
- **15 Validation Rules**: Automated checks with configurable thresholds
- **Visual Dashboards**: HTML reports with scorecards, trends, and exception tracking

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA FLOW PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£  DATA GENERATION (src/data_generation/)
    â”‚
    â”œâ”€> Synthetic Data Generator (Faker)
    â”‚   â€¢ 50,000 Customers
    â”‚   â€¢ 500 Products
    â”‚   â€¢ 200,000 Transactions
    â”‚   â€¢ 25 Marketing Campaigns
    â”‚
    â””â”€> Output: data/raw/*.csv

2ï¸âƒ£  STAGING LAYER (sql/ddl/01_staging_schema.sql)
    â”‚
    â”œâ”€> Staging Loader (src/ingestion/load_staging.py)
    â”‚   â€¢ CSV â†’ PostgreSQL
    â”‚   â€¢ Audit columns added
    â”‚   â€¢ MD5 row hashing
    â”‚
    â””â”€> Tables: stg_* (8 staging tables)

3ï¸âƒ£  TRANSFORMATION LAYER (src/transformation/)
    â”‚
    â”œâ”€> Dimension Transformation
    â”‚   â€¢ SCD Type 1 (Products, Campaigns)
    â”‚   â€¢ SCD Type 2 (Customers)
    â”‚   â€¢ Business logic applied
    â”‚
    â”œâ”€> Fact Transformation
    â”‚   â€¢ Dimension key lookups
    â”‚   â€¢ Measure calculations
    â”‚   â€¢ Aggregations
    â”‚
    â””â”€> Tables: dim_*, fact_*, agg_*

4ï¸âƒ£  QUALITY LAYER (src/quality/)
    â”‚
    â”œâ”€> Validation Engine
    â”‚   â€¢ 15+ validation rules
    â”‚   â€¢ Exception tracking
    â”‚   â€¢ Scorecard generation
    â”‚
    â””â”€> Tables: dq_* (5 quality tables)

5ï¸âƒ£  REPORTING (src/quality/quality_reports.py)
    â”‚
    â””â”€> HTML Dashboards & Excel Docs
        â€¢ Quality scorecards
        â€¢ Trend analysis
        â€¢ Data mapping docs
```

---

## ğŸ› ï¸ Technology Stack

### Core Technologies
- **Database**: PostgreSQL 12+ (dimensional modeling, indexes, constraints)
- **Programming Language**: Python 3.11+ (pandas, SQLAlchemy, Faker)
- **Data Visualization**: Matplotlib, Seaborn (embedded charts in HTML)

### Key Libraries

| Library | Version | Purpose |
|---------|---------|---------|
| `pandas` | 2.1.4 | Data manipulation and DataFrame operations |
| `SQLAlchemy` | 2.0.23 | Database ORM with 2.0 syntax |
| `psycopg2-binary` | 2.9.9 | PostgreSQL driver |
| `Faker` | 22.0.0 | Synthetic data generation |
| `loguru` | 0.7.2 | Advanced logging with rotation |
| `matplotlib` | 3.8.2 | Chart generation |
| `seaborn` | 0.13.0 | Statistical visualizations |
| `openpyxl` | 3.1.2 | Excel file generation |
| `PyYAML` | 6.0.1 | Configuration management |

### Infrastructure
- **Version Control**: Git
- **Configuration**: YAML + INI files
- **Logging**: Loguru with daily rotation and compression
- **Environment**: Python virtual environment (.venv)

---

## ğŸš€ Quick Start

### Prerequisites

1. **PostgreSQL 12+** installed and running
   ```bash
   # Check PostgreSQL version
   psql --version
   ```

2. **Python 3.11+** installed
   ```bash
   # Check Python version
   python --version
   ```

3. **Git** for cloning the repository

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/lawren-ai/enterprise-data-integration.git
   cd enterprise-data-integration
   ```

2. **Create Python virtual environment**
   ```bash
   # Windows
   python -m venv .venv
   .venv\Scripts\activate

   # Linux/Mac
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure database connection**
   ```bash
   # Copy template and edit with your credentials
   cp config/database.ini.template config/database.ini
   ```

   Edit `config/database.ini`:
   ```ini
   [postgresql]
   host = localhost
   port = 5432
   database = enterprise_dw
   user = your_username
   password = your_password
   ```

5. **Create database and schema**
   ```bash
   # Create the database
   python setup_database.py
   ```

### Running the Pipeline

```bash
# Step 1: Generate synthetic data
python src/data_generation/generate_data.py

# Step 2: Load to staging tables
python src/ingestion/load_staging.py --table all

# Step 3: Run ETL transformation
python src/transformation/run_etl.py

# Step 4: Execute data quality checks
python src/quality/quality_engine.py

# Step 5: Generate quality reports
python src/quality/quality_reports.py

# Step 6: View dashboard
start reports\quality_dashboard_*.html
```

**Expected Results:**
- âœ… 50,500 customers loaded
- âœ… 500 products loaded
- âœ… 200,000 transactions loaded  
- âœ… 419,907 transaction items loaded
- âœ… Quality score: 95.6% (12 passed, 1 warning, 2 failed)

---

## ğŸ“ Project Structure

```
enterprise-data-integration/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml              # Application settings
â”‚   â””â”€â”€ database.ini             # Database credentials (gitignored)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Source CSV files from data generation
â”‚   â””â”€â”€ processed/               # Processed output files
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ business_glossary/       # Business terms & KPI definitions
â”‚
â”œâ”€â”€ logs/                        # Daily application logs
â”‚
â”œâ”€â”€ reports/                     # Generated HTML dashboards
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ ddl/                     # Table creation scripts
â”‚   â”‚   â”œâ”€â”€ 01_staging_schema.sql
â”‚   â”‚   â”œâ”€â”€ 02_warehouse_schema.sql
â”‚   â”‚   â””â”€â”€ 04_quality_schema.sql
â”‚   â””â”€â”€ queries/                 # Sample analytical queries
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generation/         # Synthetic data generator (Faker)
â”‚   â”œâ”€â”€ ingestion/               # CSV to staging loader
â”‚   â”œâ”€â”€ transformation/          # ETL pipeline (dimensions & facts)
â”‚   â”œâ”€â”€ quality/                 # Validation engine & reports
â”‚   â””â”€â”€ utils/                   # Config, DB manager, logger
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup_database.py
â””â”€â”€ README.md
```

---

## ğŸ—„ï¸ Database Schema

### Staging Layer (6 Tables)

```
stg_crm_customers              (50,500 rows) 
stg_ecom_transactions          (200,000 rows)
stg_ecom_transaction_items     (419,907 rows)
stg_products                   (500 rows)
stg_marketing_campaigns        (25 rows)
stg_campaign_responses         (14,247 rows)
+ stg_audit_log                (tracking)
```

### Warehouse Layer (7 Tables)

#### Dimensions

**dim_customer** (SCD Type 2)
- Surrogate key: `customer_key` (auto-increment)
- Business key: `customer_id`
- SCD fields: `valid_from`, `valid_to`, `is_current`
- Metrics: `total_orders`, `total_spent` (calculated from facts)

**dim_product** (SCD Type 1)
- Surrogate key: `product_key`
- Business key: `product_id`
- Calculated: `margin_percentage = (price - cost) / price * 100`

**dim_date** (Pre-populated 2020-2030)
- Primary key: `date_key` (format: 20230115)
- Attributes: `day_name`, `month_name`, `quarter`, `is_weekend`, etc.

**dim_campaign** (SCD Type 1)
- Channels: Email, Social Media, Display Ads, Search Ads
- Calculated: `campaign_duration_days`

#### Facts

**fact_transactions** (Transaction line item grain)
- Foreign keys: `customer_key`, `product_key`, `transaction_date_key`
- Measures: `quantity`, `unit_price`, `line_total`, `discount_amount`, `net_amount`
- Degenerate dimensions: `transaction_id`, `order_number`, `payment_method`

**fact_campaign_responses** (Customer response grain)
- Foreign keys: `campaign_key`, `customer_key`, `response_date_key`
- Response types: Opened, Clicked, Converted
- Measure: `conversion_value`

#### Aggregates

**agg_customer_monthly** (Performance optimization)
- Monthly rollup: `customer_key`, `year_month`
- Pre-calculated: `total_transactions`, `total_revenue`, `avg_transaction_value`

### Quality Layer (5 Tables)

```
dq_rule_categories    - 7 quality dimensions
dq_rules              - 15 validation rules
dq_test_results       - Execution history
dq_exceptions         - Violation details (max 1000 per rule)
dq_scorecards         - Daily quality scores
```

---

## ğŸ¯ Data Quality Framework

### 7 Quality Dimensions

```
Completeness    â†’ Not null checks, required fields
Accuracy        â†’ Data format validation, range checks
Consistency     â†’ Cross-field validation, referential integrity
Validity        â†’ Business rule compliance
Uniqueness      â†’ Duplicate detection
Timeliness      â†’ Data freshness checks
Integrity       â†’ Foreign key validation
```

### Current Quality Score: **95.6%** âœ…

**Latest Results** (15 Rules Executed):
- âœ… Passed: 12 rules
- âš ï¸ Warning: 1 rule (Customer Email 3.07% missing)
- âŒ Failed: 2 rules (Transaction accuracy 20%, Phone 26% missing)

### Quality Reports

**HTML Dashboard** (`reports/quality_dashboard_[timestamp].html`):
- Quality scorecard with pass/warn/fail breakdown
- Trend analysis with matplotlib charts
- Test results table with drill-down
- Exception details (top 1000 violations)

**Executive Summary** (`reports/executive_summary_[date].txt`):
- Daily quality metrics
- Failed/warning rules summary
- Recommended actions

---

## ğŸ“š Documentation

- **[BusinessTerms.md](docs/business_glossary/BusinessTerms.md)** - Business definitions
- **[KPIDefinitions.md](docs/business_glossary/KPIDefinitions.md)** - KPI formulas with SQL

---

